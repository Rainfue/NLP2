Большую часть современной разработки в области информационных систем составляет вебразработка. Для решении этих задач наиболее
часто используются JavaScript-фреймворки.
Для того, чтобы тот или иной сайт был доступен для маркетингового продвижения за счет повышения рейтинга в результатах поисковых запросов используются специальные SEO методы.
SEO («Search Engine Optimization») – англоязычная аббревиатура, которая в переводе на русский
означает поисковая оптимизация. SEO представляет собой комплекс разного рода мероприятий
по оптимизации (внутренней и внешней) для
поднятия позиций сайта в результатах выдачи
поисковых систем по определённым запросам
пользователей [1]. Например, Google отображает
в результатах поиска ссылки на страницы, которые, исходя из своих алгоритмов, считает релевантными (соответствующими запросу) и авторитетными (качественными и уникальными с точки
зрения контента и состава гиперссылок).
Поисковая оптимизация применяется, чтобы
обеспечить доступность сайта для поисковых
систем, и чтобы повысить вероятность того,
что сайт будет найден поисковой системой среди множества других сайтов. SEO, обычно,
представляет собой набор так называемых «белых методов», которыми пользуются производители веб-контента и веб-мастера для повышения ранжирования сайта [2, 3].
Однако иногда, ввиду широкой развитости
некоторых веб-технологий, в частности,
JavaScript-фреймворков, SEO-оптимизация
веб-приложений затрудняется или даже полностью не работает, поскольку в погоне за скоростью работы веб-приложений приходится пересматривать подходы в разработке веб-сайтов.
В данной статье будут рассмотрены вопросы
использования подходов, позволяющих современным веб-приложениям, использующим
JavaScript-фреймворки, не терять свою SEOориентированность.
Работа поисковых роботов сложна по своему устройству. Они используют множество
разных алгоритмов, которые усложняются с
каждым днём.
Поисковые системы используют переменную PageRank для того, чтобы определить релевантность той или иной страницы и, тем самым, поднять её в рейтинге ранжирования.
Общую формулу PageRank для любой страницы можно выразить следующей формулой:
( )
( ) u
u B
PR v PR
L v ?
?? . (1)
Таким образом, значение PageRank для страницы u зависит от значений PageRank для каждой
страницы v, содержащихся в наборе Bu (набор
всех страниц, ссылающихся на страницу u), деленных на число L(v) ссылок на странице v [4].
Предполагается, что при расчете PageRank
страницы, у которых нет исходящих ссылок,
свяжутся со всеми остальными страницами
коллекции. Поэтому их значения PageRank разделяются поровну между всеми остальными
страницами. То есть, чтобы справедливо распределить рейтинг релевантности со страницами, которые не являются поглотителями, эти
случайные переходы добавляются ко всем узлам в Интернете, с остаточной вероятностью,
обычно равной 0,85 (d = 0,85), из расчета частоты, которую средний пользователь использует
для своего браузера.
Итого, конечное уравнение выглядит следующим образом:
1 ( )
( )
( ) j pi
j
i p M
j
d PR p
PR p d
N L p ?
?
? ? ?
(2)
где PR – PageRank,
pi – узел (страница), чей PR рассчитывается
в данный момент,
d – коэффициент затухания, который показывает вероятность того, что пользователь запросит другую случайную страницу во время
просмотра сайта. Принято считать коэффициентом затухания значение 0,85 согласно рекомендациям разработчиков данного алгоритма.
А оставшаяся вероятность в 0,15 – это вероятность того, что пользователь не перейдёт по
ссылке дальше, а закроет вкладку браузера,
N – общее количество активных узлов, участвующих в расчёте,
i
j p p M? – множество узлов (страниц),
имеющих отношение к текущему узлу

PR(pj) – PageRank для каждой страницы pj
,
которая ссылается на текущую pi
,
L(pj) – кол-во ссылок с узла pj
, ссылающегося в том числе и на узел pi
.
То есть PageRank использует весь контент
веб-приложения/сайта, и на базе этого даёт ему
соответствующую оценку. Поэтому важно,
чтобы поисковому роботу Google был доступен
весь контент веб-приложения в одну единицу
времени. Иначе значение переменной PageRank
будет ниже, чем могло бы быть, и соответственно, веб-приложение будет на более низких
позициях при поисковой выдаче [5].
Что касается алгоритма ранжирования сайтов от Яндекс, то он был представлен в 2006
году. Одним из вариантов ранжирования является использование текста запроса. Для этого
производится вычисление так называемого
Score (метки) запроса [6].
Сама встречаемость слова (релевантность)
определяется по следующей формуле:
1 2
log( ) single
TF
W p
TF k k DocLength
? ?
? ? ?
, (3)
где p – условное обозначение веса слова, для
которого вычисляется релевантность,
TF – число вхождений леммы в документ,
k1, k2 – коэффициенты,
DocLength – длина документа в количестве
слов.
Наличие всех слов в запросе определяется
следующей формулой:
0, 2 log( ) W p AllWords i
? ?? , (4)
где pi – вес конкретного i-го слова в общем наборе слов запроса.
То есть, производится вычисление суммы
всех слов в запросе. Но, по сути, главные алгоритмы Яндекс работают таким же образом, как
и алгоритмы Google, то есть важно сделать так,
чтобы роботам был доступен весь контент сайта в момент загрузки.
Данная особенность поисковых движков не
позволяла раньше использовать веб-приложения на JavaScript-фреймворках в тех проектах,
где SEO-ориентированность была определяющим фактором.
Разработки на чистом JavaScript в сегменте
крупных веб-приложений, практически нет. В
основном используются фреймворки JavaScript.
На сегодняшний день три самых популярных
из них - React, Angular и Vue.
Стек технологий – это набор структур и инструментов, используемых для разработки программного продукта. Этот набор фреймворков
и инструментов специально выбран для совместной работы при создании хорошо работающего программного обеспечения.
Вот несколько примеров широко используемых сегодня стеков технологий веб-разработки:
? MERN (MongoDB, ExpressJS, ReactJS,
NodeJS);
? LAMP (Linux, Apache, MySQL, PHP);
? MEAN (MongoDB, ExpressJS, AngularJS,
NodeJS) [7].
Например, стек MERN – это набор инструментов для веб-разработки. Он состоит из рабочих компонентов MongoDB, ExpressJS,
ReactJS и NodeJS. Структура данного стека показана на Рис. 1.
Как показано на рисунке, пользователь
взаимодействует с компонентами пользовательского интерфейса ReactJS, который работает в браузере. Его интерфейс обслуживается
серверной частью приложения, находящейся на
сервере, через ExpressJS, работающий поверх
NodeJS [8].
Любое взаимодействие, вызывающее запрос
на изменение данных, отправляется на сервер
Express, который в свою очередь создан на основе NodeJS, который при необходимости получает данные из базы данных MongoDB и возвращает данные во внешний интерфейс
приложения, которые затем отображаются конечному пользователю.
React – это JavaScript-библиотека с открытым исходным кодом для разработки пользовательских интерфейсов. В основе всех Reactприложений лежат компоненты [9]. Компонент
– это автономный модуль приложения, который
обладает собственным функционалом и представляет собой определенный отдельный элемент интерфейса (кнопка, поле ввода, строка
навигации, пагинация и т.д.). Компоненты служат строительными блоками интерфейса программы. Одним из главных преимуществ React
является высокая производительность. Стратегия взаимодействия в React с DOM и является
основной идеей Virtual DOM от React (Рис. 2).
Virtual DOM представляет собой дерево узлов, в котором перечислены элементы, также
их атрибуты и различный контент, такие как
объекты и свойства. Метод render создает дерево узлов из компонентов React и обновляет это
дерево в ответ на изменения в модели данных,
вызванные действиями [10].
Каждый раз, когда базовые данные изменяются в приложении React, создается новое
представление пользовательского интерфейса,
виртуального DOM. Это всё в совокупности
образует стандартное SPA-приложение. На
Рис. 3 показана схема создания стандартного
веб-приложения на JavaScript-фреймворках, так
называемый клиент-ориентированный подход.
Данный подход полностью отвечает концепции SPA-приложений, однако добавляет
большую проблему – нарушение SEOориентированности приложения.
Существует несколько таких решений. Первое, и самое главное, это максимальное использование на клиенте статических страниц.
То есть весь основной контент пишется на
HTML и CSS [7, 11]. Но в таком случае, все
плюсы от использования JavaScript- фреймворков сходят на нет, так как скорость работы
приложения становится намного меньше, и динамичность веб-приложений исчезает (Рис. 4).
По сути, данный метод решения проблемы возвращает веб-разработку на 10-15 лет назад, когда вся сеть Интернет была статической, а JavaScript использовался только для добавления
некоторой интерактивности на страницу, например, работа слайдеров и меню.
Другой метод решения данной проблемы –
пререндеринг (предварительный рендеринг).
Данный метод позволяет использовать некоторые готовые библиотеки, благодаря которым
удаётся перехватывать запрос поискового робота. То есть, разработанное веб-приложение
понимает, что сейчас его сканирует поисковый
робот и выдаёт роботу статический HTML
(Рис. 5). Данный метод довольно прост в реализации, и как было сказано выше, имеет некоторые готовые решения [11].
Однако поисковый робот на самом деле состоит из двух специализированных малых роботов. Первый заходит на страницу и сканирует
статику, то есть HTML. После него заходит на
страницу второй робот и проходит уже по JavaScript сценариям. То есть, разработка данным
методом не даст высокую гарантию правильного сканирования, поскольку на момент работы
первого поискового робота на странице может
не быть никакого контента, а веб-приложение
не поймёт, что зашёл робот.
У архитектуры SPA-типа огромный минус –
это долгий первый запуск, поскольку нужно
ждать, пока всё приложение загрузится с сервера. Исследования показывают, что ожидание
загрузки более двух секунд не является приемлемым для большинства пользователей, и они
могут просто закрыть страницу не дождавшись
загрузки. Одним из преимуществ изоморфного
подхода к созданию приложений является то,
что рендеринг происходит на сервере, и становится возможным отображать компоненты после загрузки страницы на клиенте [12].
Работа изоморфного приложения заключается не в замене традиционного серверного
API, а в устранении долгого ожидания загрузки
страницы. К тому же SPA-приложения плохо
взаимодействуют с SEO-инструментами и могут быть не проиндексированы полностью поисковыми системами. При изоморфных приложениях изначально отправляется обычная
HTML страница, которая быстро загружается и
показывается клиенту. Когда обрабатываются
компоненты React (или другого js-фреймворка,
далее именно на примере React) на сервере и
отправляется HTML-код клиенту, React на стороне клиента замечает, что HTML уже существует [9]. Данный фреймворк просто прикрепляет обработчики событий к существующим
элементам по необходимости [13]. Этот подход
увеличивает производительность приложения,
также ускоряя процесс разработки (Рис. 6).
Для работы с данными в изоморфном приложении выделяют две стратегии:
1. Загрузка пользовательских данных до клиентского отображения. Преимущество в том, что
на клиент приходит полный контент, но, если загрузка данных на сервере будет слишком долгой,
пользователь будет видеть пустую страницу и,
скорее всего, покинет приложение.
2. Загрузка пользовательских данных после
клиентского отображения. С данной стратегией
интерфейс получается более отзывчивым, но
после первого отображения необходимо производить ререндеринг (повторный рендеринг)
представления с дозагруженными данными.
Каждая из стратегий имеет свои особенности, и выбор стратегии производится от конкретной предполагаемой модели использования
приложения.
Стандартный сценарий для создания изоморфного приложения может включать в себя
разного рода инструменты. Например, AWS
Lambda – это бессерверный вычислительный
сервис, который реагирует на определенные
события приложения, запуская в ответ на них
соответствующий программный код и отвечает
за автоматическое выделение необходимых вычислительных ресурсов для стабильной работы
приложения.
Стек AWS компонентов может быть следующим:
? AWS Amplify – высокоуровневая платформа для управления сервисами AWS, в основном для мобильной и веб-разработки;
? AWS Lambda – запуск кода в облаке без
управления серверами;
? AWS Cloudfront (CDN) – сеть доставки
контента;
? AWS Simple Storage Service (S3) – хранение статических ресурсов.
На Рис. 7 показана архитектура изоморфного приложения с помощью вышеперечисленных инструментов.
В листинге кода 1 показан стандартный
базовый App React приложения, построенного
на изоморфной архитектуре. По сути, оно ничем не отличается от базового стандартного
приложения.
Ниже показан листинг кода 2 серверного JavaScript, в котором показана генерация и отправка HTML-файлов на клиентскую сторону, которая и позволит поисковым роботам увидеть
контент ещё до загрузки всего приложения.
Вышеприведенный подход позволяет полностью решить проблему недостаточного или
нулевого ранжирования SPA-приложений, построенных на JavaScript-фреймворках. Он позволяет отправлять статические файлы с контентом на клиентскую часть независимо от самого приложения (Рис. 8).
Основные подходы к созданию изоморфного
приложения включают в себя несколько важных факторов:
? общая часть приложения не должна зависеть от среды исполнения;
? функциональность, зависящая от среды
исполнения, должна быть вынесена в отдельный модуль;
? для клиентской и серверной части приложения должен быть общий роутер, потому
что рендер по URL на клиенте и на сервере
должен давать одинаковый результат;
? так как на каждый запрос сервер должен
создавать новое состояние приложения, то в
приложении не должно быть синглтонов и глобальных переменных;
Листинг кода 1. Базовый App.js файл
import React from 'react';
import './App.css';
function App() {
 return (
 <div className="My-App">
 <header className="My-app-header">
 Server Rendered React App
 </header>
 </div>
 );
}
export default App;
? на стороне сервера не нужно применять
систему реактивности, так как в ней нет необходимости, потому что сервер просто создаёт
статическую разметку.
На Рис. 9 показан сравнительный график
использования изоморфного приложения со
стандартным приложением.
Листинг кода 2. Отправка статического контента
const express = require('express');
const awsSEM = require('aws-serverless-express/middleware');
const fs = require('fs');
const bodyParser = require('body-parser');
const render = require('./client/render').default;
const expApp = express();
expApp.use(bodyParser.json())
expApp.use(awsSEM.eventContext())
expApp.use(function(req, res, next) {
 res.header("Access-Control-Allow-Origin", "*")
res.header("Access-Control-Allow-Headers", "Origin, X-Requested-With, ContentType, Accept")
 next()});
expApp.get('*', function(req, res) {
// Чтение файла index.html из the create-react-app build
 const html = fs.readFileSync("./client/index.html", "utf-8");
// Рендеринг приложения react на стороне сервера
 const markup = render();
// Отправка статического контента клиенту
 res.send(html.replace(`<divid="root"></div>`,`<div
id="root">${markup}</div>`))});
module.exports = expApp;
Таким образом, поисковые роботы смогут
легко сканировать контент приложения, и поисковый рейтинг у сайта, использующего изоморфный подход, будет таким же, как у обычного статического сайта.
В ходе исследования проблемы было выяснено, что существующие методы пререндеринга и работа со статическим HTML не позволяют полностью использовать возможности
веб-приложения, либо же приводят к недостаточному сканированию веб-сайтов поисковыми
роботами. Соответственно, SEO-ориентированность этих сайтов ухудшается.
Предложенное в статье решение данной
проблемы, а именно использование изоморфного подхода позволяет решить вопрос SEOориентированности путём предварительной загрузки статических страниц с контентом сайта.
Таким образом, можно быть уверенным, что
поисковый робот, когда бы он ни просканировал страницу, сможет обнаружить контент и
сможет его проиндексировать.
В статье показаны варианты использования
и построения изоморфного приложения. Соблюдение этих правил позволяет получить правильное изоморфное приложение, которое
практически закрывает проблему SEO-ориентированности SPA-приложений.
1. Дыкан А. Клиентское SEO. М.: Эдитус, 2016. 280