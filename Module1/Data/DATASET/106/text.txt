Суперкомпьютеры обрабатывают данные, которые могут содержать 
конфиденциальную информацию. Учитывая насколько большой объем 
данных, они могут обрабатывать, им нужен соответствующий уровень 
защиты. Рассмотрим проблемы, которые могут вызвать сбои в работе 
устройства и методы их устранения. Одна из наиболее важных проблем 
— это угрозы извне, специально созданные человеком, чтобы заполучить конфиденциальную информацию. На данный момент для предотвращения этого используется криптография. 
С помощью сложных математических задач зашифровывается информация и создается ключ шифрования, без которого получить начальные данные очень сложно. Однако суперкомпьютер может сравнительно быстро перебрать множество вариаций шифровок и подобрать 
нужный ключ. Время подбора будет зависеть от сложности математической задачи. Это значит, что суперкомпьютер может стать одновременно и проблемой защиты данных, и ее решением, ведь он способен 
создавать более сложные схемы зашифровки.
Рассмотрим подробнее сами методы шифрования. Криптографические алгоритмы делятся на бесключевые, одноключевые и двуключевые. 
Бесключевой подразделяется на хеширование. Одноключевые алгоритмы подразделяются на хеширование и симметричное шифрование. 
Двухключевые подразделяются на асимметричное шифрование, которое включает в себя электронную подпись [2].
Хешироване — это не просто кодировка исходной информации, а индивидуальная метка, создающаяся для каждого набора данных. Независимо от начальной длины строки на выходе получится фиксированное 
число элементов в зависимости количества бит целочисленных значений. Из-за этого возможны коллизии (одинаковые шифровки от разных 
изначальных данных), однако в виду сложности математической функции вероятность совпадения сводится к минимуму [2].
 В ассиметричной системе используется публичный и приватный 
ключ. Первый имеется в свободном доступе и шифрует сообщение. 
Однако для расшифровки он не подходит, и без приватного ключа, который передается только получателю, распознать сообщение почти невозможно. Это нужно для того, чтобы безопасно передавать сообщение 
по общедоступным каналам связи. Только приватный ключ идет напрямую к получателю [1].
Электронная подпись схожа с ассиметричным шифрованием, однако 
она создана не просто для передачи информации, а для подтверждения 
того, что сообщение пришло от источника. Таким образом, получатель 
будет уверен, что у него оригинальное послание. Создаются алгоритмы 
электронной подписи на основе хэш-функций. Свойства криптографически стойкой хэш-функции обеспечивают надежность электронной 
цифровой подписи. Действительно, если изменить в оригинальном сообщении хотя бы один символ, его хэш, а, следовательно, и цифровая 
подпись, изменится, а подобрать другое сообщение с таким же хэшем 
практически невозможно. Наиболее распространенными алгоритмами 
ассимметричного шифрования являются RSA (Rivest-Shamir-Adleman) 
и DSA (Digital Signature Algorithm).
RSA основан на факторизации больших простых чисел. Он применим 
для шифрования и дешифрования электронных подписей и сообщений. RSA является одним из самых надежных алгоритмов, однако для 
работа алгоритма трудоемка, а, значит, и сам процесс занимает много 
времени [3].
DSA — алгоритм, созданный на основе дискретного логарифмирования и модульного возведения в степень. Он используется для создания 
и проверки цифровой подписи. DSA имеет высокий уровень прочности, 
относительно быструю скорость расшифровки, однако для шифрования 
алгоритму требуется больше времени, чем RSA для аналогичной операции [3].
Симметричным считается любой шифр, использующий один и тот же 
секретный ключ для шифрования и расшифровки. Современные симметричные алгоритмы считаются надежными, если отвечают следующим требованиям:
• Наиболее повторяющиеся символы исходного текста не должны соответствовать наиболее используемым символам шифра.
• Шифр должен быть не линейным, в нем не должно быть закономерностей, которые можно отследить, используя несколько открытых 
текстов и их шифровок 
Наиболее часто известные алгоритмы симметричного шифрования 
— это DES (Data Encryption Standard), 3DES (Triple DES), AES (Advanced 
Encryption Standard), Blowfish [1].
DES — это симметричный алгоритм шифрования, разработанный в 
1970-х годах и принятый в качестве стандарта национальным институтом стандартов и технологий США. Он имеет размер блока 64 бита и 
работает на основе сети Фейстел [1].
3DES — является алгоритмом тройного шифрования данных, применяет алгоритм DES три раза к каждому блоку. Он имеет размер блока 
64 бита и длину ключа 112 или 168 бит. На данный момент ни один из 
этих алгоритмов уже не используется, в виду того, что их довольно просто взломать, однако они внесли большой вклад в историю развития 
криптографии [1].
AES — симметричное шифрование, основанное на блочной системе. 
Длина ключа шифрования может быть 128, 192 и 256 бит, однако длина 
его блока всегда фиксирована и равна 128 битам. Алгоритм использует 
сеть подстановок-перестановок, что делает его относительно быстрым 
и наиболее надежным алгоритмом [1].
Blowfish также, как и AES основан на блочной системе с варьирующейся длиной ключа от 32 до 448 бит и размером блока 64 бит. Blowfish 
использует большое количество предварительно вычисленных значений, блоков, которые создаются на основе ключа и используются для 
замены и перестановки битов данных. Данный алгоритм постепенно 
начинает устаревать, он уступает в надежности и скорости AES, однако 
его всё еще тяжело взломать, поэтому он широко используется [1].
Создание квантовых компьютеров позволило решать задачи нового 
уровня сложности во многих сферах деятельности. Например, в медицине, логистике, а так же в квантовой криптографии. Как говорилось ранее, 
алгоритмы шифрования рассчитаны на то, что третья сторона не сможет 
их взломать ввиду сложности самого алгоритма, но если ей это всё-таки 
удастся, то ни отправитель, ни получатель сообщения об этом не узнают. 
Квантовая криптография способна помочь решить данную проблему. 
Рассмотрим ее на примере протокола ВВ84. Отправитель посылает 
фотоны, поляризованные в одном из двух неортогональных друг другу базисах (прямоугольном и диагональном). Получатель случайным образом проверяет поляризацию некоторых базисов. По открытым каналам передаются данные об использованных базисах. Данные полученные при не совпавших базисах сбрасываются. 
Если третья сторона перехватит одиночный фотон и отправит его 
копию, то количество ошибок в распределяемом квантовом ключе вырастет. Безопасность линии связи можно гарантировать при уровне 
ошибок менее 11%.
Однако в совмещении квантовых технологий и суперкомпьютеров 
не обходится без трудностей. Для введения новых технологий требуется создание системы интеграции между классическими и квантовыми 
компьютерами. Также квантовые компьютеры всё еще имеют технические ограничения, связанные с декогеренцией, шумами, ошибками и 
интерференцией. Нельзя не учитывать и содержание данных устройств. 
Для стабильной работы только суперкомпьютера требуется порядка 30 
мегаватт энергии и 20 тысяч тонн воды для охлаждения системы [4]. 
Помимо этого сбой в работе суперкомпьютера могут вызвать недочеты в программном обеспечении (ПО) системы. Для работы суперкомпьютера требуется большие и сложные программы, поэтому мелкие 
недочеты вполне возможны в коде устройства, однако даже они могут 
стать причиной взлома этого устройства. Устраняется данная проблема 
с помощью фаззинга. Данный метод заключается в тестировании программы, т.е. подачи данных и анализа результатов. 
Сложность фаззинга заключается не только в том, чтобы данных, отправленных на проверку, было достаточно для выявления всех ошибок, 
но и в сравнении предполагаемых результатов с реальными. Это значит, 
что каждый такой код проверки должен быть разработан под индивидуальную задачу, и нельзя взять готовый алгоритм, не модернизировав 
его под конкретные условия. Иногда проверяют и исходный код, создавая алгоритмы проверки, или совмещает эту проверку с фаззингом. 
Как правило, проверка кода состоит из следующих этапов:
1. Определение цели — в первую очередь проверяются те элементы, в 
которых вероятность нахождения ошибки наибольшая, например библиотеки. Если заранее известно, какой именно элемент нужно проверить, то этот шаг опускают.
2. Определение направлений ввода — анализ документации и составление программы на основе полученных данных.
3. Подготовка данных — обычно условия заранее вставляются в программу, или генерируется с помощью функций [5].
Так же на работу суперкомпьютеров влияют внешние факторы, например и излучение из космоса. Естественно такие случаи происходят 
редко, однако их тоже нужно учитывать. Это происходит из-за воздействия медленных нейтронов (нейтроны с энергией на 9 порядков меньшей, чем у обычного нейтрона). Частица сталкивается с бором-10, и 
элемент распадается на литий и альфа частицу. Это приводит к сбоям 
в работе устройства. Эту проблему может частично решить использование более чистого бора (бор-11), однако это повысит стоимость оборудования. Также добавляется программа для периодической проверки 
результатов, в случае распада нейтрона, устройство покажет этап, на 
котором оно зафиксировало ошибку, однако на это будет требоваться 
большое количество памяти [6].
Таким образом, суперкомпьютер — это устройство невероятного 
масштаба, способное кардинально влиять на развитие современного 
мира, поэтому так важно сохранять их надежность. Главной проблемой 
суперкомпьютеров является взлом данных. Методы их шифрования с 
каждым разом становятся всё сложнее и надежнее, как и методы взлома. Основные сбои в работе ПО устройства, если это возможно, устраняются на ранних стадиях разработки и запуске системы, однако на 
некоторые моменты, такие как космическое излучение, повлиять практически невозможно. 