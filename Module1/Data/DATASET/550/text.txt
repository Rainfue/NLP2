Интернет – это огромное хранилище информации. Искомая информация можетхраниться на
множестве сайтов, тем самым возникаеттрудность в получении полнойкартины о предмете поиска.
Ручной сбор и обработка информациизанимает много времени ресурсов. Важным фактором является
то, что эта информацияпостоянно изменяется. Временами она меняется ежеминутно, тем самым
усложняяработу. Парсинг сайтов является наилучшим и эффективным решением автоматизациисбора
и обработки информации.
Парсинг – это принятое в информатике определение последовательного синтаксическогоанализа
информации, размещённой на интернет - страницах. Парсер – это программа илискрипт, позволяющая
выполнить такой анализ и представить результат в нужном дляпользователя виде.
Рассмотрим случаи использования парсеров.
Первый случай, когда существует объединение нескольких потоков информации из разных источников водном хранилище, базе данных или интернет – странице, а также необходимо ее постоянное
обновление.Например, когда возникает необходимость сбора информации о предложениитрудоустройства с различных сайтов на одном. Такой сайт позволит отслеживать всеобъявления и быть одним из
первых откликнувшихся на предложение работодателя.
Второй случай, когда необходима модернизация информации до наиболее актуальной на определенный момент времени. В такомслучае ручное редактирование очень энергозатратно и требует больших
затрат времени ичеловеческих ресурсов. Например, сайты отображения погоды, курса валют и т.д.
И наконец, частичное или полное копирование информации сайта с целью размещенияеё на своих
ресурсах. При этом полученная информация может быть заранееобработана для увеличения своей уникальности. Зачастую к парсингу прибегают сайтымагазинов с отзывами о какой - либо продукции.
Одной из проблем парсинга страниц является наличие некорректного кода в тексте.Сюда можно отнести незакрытые теги, символы <> внутри тегов, значения атрибутов безкавычек. Страницы с такими ошибками не всегда можно восстановить, но можнопривести их к такому виду, к которому приводит браузер.
Также стоит иметь в виду, что множество html - страниц, встречающихся в интернете, являются в
какой либо степени некорректными. Таким образом, необходимо разрабатыватьнестрогий парсер, способный обрабатывать некорректный html код. Другой проблемойявляется то, что некоторые сайты с легкостью распознают, когда их страницу пытаютсяспарсить, тем самым блокируют доступ к коду страницы.
Кроме того, некоторые сайтыпредоставляют информацию только после прохождения авторизации на
сайте. Также нестоит забывать про блокировку некоторых ресурсов из других стран по IP. И наконец,
встречаются сайты, которые медленно или частично загружаются, либо работаютнестабильно.
Процесс парсинга html - страницы можно разделить на три основных этапа внезависимости от
языка, на котором он написан.
Получение исходного кода html - страницы. На этом этапе выполняется копированиеисходного
кода страницы с дальнейшим извлечением из неё информации. В различныхязыках для этого используются определённые способы. Чаще всего коды страницизвлекаются при помощи специальных библиотек либо регулярных выражений.
Информация может быть извлечена немедленно или вы можете сохранить HTML-страницы для
дальнейшей обработки в оригинальном (около 100 КБ) или сжатом (15 КБ) размере. Процедура сканирования сайта для извлечения данных зависит от его размера и структуры. Большинство современных сайтов представляют собой очень сложные конфигурации большого количества страниц со ссылками друг
на друга, напоминающие веб. Существует две стандартные стратегии обхода: по глубине и по ширине.
Преимуществами первой стратегии являются: небольшой размер очереди запросов, удобство
перебирать страницы одного сайта, а ее недостаток заключается в том, что она может не подходить
для обхода всех звеньев (поскольку глубина может быть очень большой или бесконечной).
Преимущество второй стратегии заключается в том, что онаподходит для обхода всех ссылок на
сайте, а недостатками выступают большой размер очереди, а также возможные проблемы глубины в
графе ссылок.
Следующим шагом является извлечение необходимой информации из полученного кода. Получив
исходный код html - этой страницы для обработки. Таким образом, он отделяет требуемый текст от разметки гипертекста, создает иерархическое дерево элементов документа (DOM) и содержит требуемую информацию со страницы. Вам нужно найти неправильный код или открыть тег, который отвечает на ошибку. Затемнаписатьпарсер. Также, необходимо понимать, что нужная информация может быть разделена на несколько страниц. В этом случае после объявления всех шагов необходимо перейти на следующую страницу, чтобы выполнить этот раздел, и указать, что информация не передается. При больших объемах выборки данных нужно оптимизировать скорость и частоту запросовтаким образом, чтобы не нарушить работу
сайта и не быть заблокированным из - за частыхавтоматических запросов. Решением данной проблемыможет послужить разбиение процесса извлечения данных на несколько процессов: например, разделивмежду ними url - ы, чтобы в рамках одного процесса осуществлялся парсинг одного сайта.
Последний шаг – сохранение результата. После успешного извлечения данных страницыих
необходимо сохранить для дальнейшей обработки. Сохранятьрезультат можно в базу данных, форматировать в excel, загружать на страницу взависимости от поставленной задачи.