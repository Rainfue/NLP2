Стремясь воспроизвести функции человеческого мозга, первые исследователи 
ИНС в 1940-е гг. создали простые аппаратные модели биологического нейрона и 
системы его соединений. Эти модели были достаточно грубыми аппроксимациями. Тем 
не менее, с их помощью были получены результаты, стимулировавшие дальнейшие 
исследования, приведшие к созданию более сложных сетей [1].
Происхождение алгоритмов классификации образов связано с попытками 
глобального осмысления деятельности мозга. Американский ученый Ф. Розенблатт в 
1957 году предложил перцептронный («узнающий») алгоритм, который представляет 
собой одну из первых моделей процессов запоминания и организации информации, 
реализуемых мозгом. Перцептрон Розенблатта произвел ошеломляющее впечатление 
на современников. Он впервые указал на реальные возможности алгоритмизации 
интеллектуальной деятельности и привел к созданию нового направления 
исследований, получившего название «Распознавание образов» [2]. Однако, позже 
было строго доказано, что первоначальная схема перцептрона, предложенная 
Розенблаттом, не обладает нужной способностью к экстраполяции, т.е. к 
распознаванию объектов, не учувствовавших в процессе обучения. Попытки 
усовершенствовать перцептрон, предпринятые в разное время отдельными 
сторонниками этой схемы, также не привели к ощутимым положительным результатам. 
Назрела необходимость создания полноценной серьезной теории параллельных 
вычислительных устройств, подобных перцептрону, теории, учитывающей специфику 
конкретных задач и позволяющей прогнозировать разрешимость тех или иных задач 
[3].
В основе перцептрона лежит математическая модель восприятия информации 
мозгом. Разные исследователи по-разному его определяют. В самом общем своем виде 
(как его описывал Розенблатт) он представляет систему из элементов трех разных 
типов: сенсоров, ассоциативных элементов и реагирующих элементов [4]. 
Перцептрон, или перцептрон – математическая или компьютерная модель 
восприятия информации мозгом (кибернетическая модель мозга), предложенная 
Фрэнком Розенблаттом и впервые реализован в видел электронной машины «Марк-1» в 
1960 г. Перцептрон стал одной из первых моделей нейросетей, а «Марк-1» - первым в 
мире нейрокомпьютером.
Сигналы от возбужденных A-элементов, в свою очередь, передаются в 
сумматора R, причем сигнал от i-го ассоциативного элемента передается с 
коэффициентом. Этот коэффициент называется весом AR связи.
Так же как и A-элементы, R-элемент подсчитывает сумму значений входных 
сигналов, умноженных на веса (линейную форму). R-элемент, а вместе с ним и 
элементарный перцептрон, выдает «1», если линейная форма превышает порог θ, иначе 
на выходе будет «1». Математически, функцию, реализующую R-элемент, можно 
записать так:
Рисунок 2. Формула, реализующая R-элемент
Обучение элементарного перцептрона состоит в изменении весовых 
коэффициентов связей AR. Весы связей SA (которые могут принимать значения (-1, 0, 
1)) и значение порогов A-элементов выбираются случайным образом в самом начале и 
потом не меняются.
После обучения перцептрон готов работать в режиме распознавания или 
обобщения. В этом режиме перцептрона предъявляются ранее неизвестные ему 
объекты, и он должен установить, к какому классу они принадлежат. Работа 
перцептрона состоит в следующем: при предъявлении объекта, возбуждены Aэлементы передают сигнал R-элемента равна сумме соответствующих коэффициентов. 
Если эта сумма положительна, то принимается решение, что данный объект относится 
к первому классу, а если она отрицательна — то ко второму.
Важным свойством любой нейронной сети является способность к обучению. 
Процесс обучения является процедурой настройки весов и порогов с целью 
уменьшения разницы между желаемыми (целевыми) и получаемыми векторами на 
выходе. В своей книге Розенблат пытался классифицировать различные алгоритмы 
обучения перцептрона, называя их системами подкрепления.
Система подкрепление — это любой набор правил, на основании которых 
можно менять с течением времени матрицу взаимодействия (или состояние памяти) 
перцептрона.
Описывая эти системы подкрепления и уточняя возможные их виды, Розенблат 
основывался на идеях Д. Хебба об обучении, предложенных им в 1949 году, которые 
можно перефразировать в следующее правило, которое состоит из двух частей:
 Если два нейроны с обеих сторон синапса (соединения) активизируются 
одновременно (то есть синхронно), то прочность этого соединения 
возрастает.
 Если два нейроны с обеих сторон синапса активизируются асинхронно, то 
такой синапс ослабляется или вообще отмирает.
Обучение с учителем. Классический метод обучения перцептрона — это метод 
коррекции ошибки. Он представляет собой такой вид обучения с учителем, при котором 
вес связи не изменяется до тех пор, пока текущая реакция перцептрона остается 
правильной. При появлении неправильной реакции вес изменяется на единицу, а знак 
(+/-) определяется противоположным от знака ошибки.
Допустим, мы хотим научить перцептрон разделять два класса объектов так, 
чтобы при предъявлении объектов первого класса выход перцептрона был 
положительный (1), а при предъявлении объектов второго класса — отрицательным (-
1). Для этого выполним следующий алгоритм:
1. Случайно выбираем пороги для A-элементов и устанавливаем связи SA 
(далее они не будут меняться).
2. Начальные коэффициенты считаем равными нулю.
3. Предъявляем обучающую выборку: объекты (например, круги или 
квадраты) с указанием класса, к которому они принадлежат. 
o Показываем перцептроны объект первого класса. При этом 
некоторые A-элементы пробудятся. Коэффициенты, 
соответствующие этим возбуждением элементов, увеличиваем на 1.
o Предъявляем объект второго класса, и коэффициенты тех Аэлементов, которые возбудились при этом показе, уменьшаем на 1.
4. Обе части шага 3 выполним для всей обучающей выборки. В результате 
обучения сформируются значения весов связей.
Теорема сходимости перцептрона, описана и доказана Ф. Розенблат (при 
участии Блока, Джозефа, Кести и других исследователей, которые работали вместе с 
ним), показывает, что элементарный перцептрон, обученный по такому алгоритму, 
независимо от начального состояния весовых коэффициентов и последовательности 
появления стимулов всегда приведет к достижению решения по конечный промежуток 
времени.
Обучение без учителя. Кроме классического метода обучения перцептрона, 
Розенблат также ввел понятие об обучении без учителя, предложив следующий способ 
обучения:
 Альфа-система подкрепления — это система подкрепления, при которой 
веса всех активных связей, ведущих к элементу, изменяются на 
одинаковую величину r, а веса неактивных связей за это время не 
меняются.
Позже, с разработкой понятия многослойного перцептрона, альфа-система была 
модифицирована, и ее стали называть дельта-правилом. Модификацию было 
проведено с целью сделать функцию обучения дифференцируемой (например, 
сигмоидною), что в свою очередь требуется для применения метода градиентного 
спуска, благодаря которому возможно обучение более одного слоя [5].
Алгоритм обучения перцептрона может быть реализован на цифровом 
компьютере или другом электронном устройстве, и сеть становится в определенном 
смысле самоподстраивающейся. По этой причине процедуру подстройки весов обычно 
называют «обучением» и говорят, что сеть «обучается». Доказательство Розенблатта 
стало основной вехой и дало мощный импульс исследованиям в этой области. Сегодня 
в той или иной форме элементы алгоритма обучения перцептрона встречаются во 
многих сетевых парадигмах.